{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis of the US Stock Financial indicators data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names of contributors: Anene Ifeanyi, Chizitere Igwe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date: 2020-12-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Summary](#Summary)\n",
    "2. [Method](#Method)\n",
    "3. [Data](#Data)\n",
    "4. [Partition Data into train and test splits](#PartitionDataintotrainandtestsplits)\n",
    "5. [Exploratory Data Visualisations](#ExploratoryDataVisualisations)\n",
    "6. [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary <a name=\"Summary\"></a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method <a name=\"Method\"></a>\n",
    "\n",
    "Given the financial stock indicators, should a hypothetical investor buy the stock or not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data <a name=\"Data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required exploratory data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, RandomizedSearchCV\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    PolynomialFeatures,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "\n",
    "# classifiers / models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, RidgeCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Others\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.metrics import f1_score, mean_squared_error, make_scorer, recall_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this exploratory data analysis, we will only be working with the 2014 dataset. The techniques applied here can be applied to the other datasets.\n",
    "\n",
    "df_2014 = pd.read_csv('../data/raw/2014_Financial_Data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = df_2014.rename(columns={'Unnamed: 0': 'Ticker'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Results <a name=\"PartitionDataintotrainandtestsplits\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_2014, train_size = 0.75, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y train\n",
    "\n",
    "X_train, y_train = (train_df.drop(columns = [\"Class\"]), train_df[\"Class\"])\n",
    "\n",
    "X_test, y_test = (test_df.drop(columns = [\"Class\"]), test_df[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and transformations\n",
    "\n",
    "drop_features = [\"Ticker\"]\n",
    "\n",
    "categorical_features = [\"Sector\"]\n",
    "\n",
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "#len(numerical_features) == 222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Ticker` column was dropped because it does not seem to add any significant contribution to prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(StandardScaler(), SimpleImputer())\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_features),\n",
    "    (numeric_transformer, numerical_features),\n",
    "    (OneHotEncoder(handle_unknown = \"ignore\"), categorical_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function \n",
    "\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns the mean and standard deviation of cross validation scores\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "    \n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    \n",
    "    out_col = []\n",
    "    \n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "    \n",
    "    return pd.Series(data = out_col, index = mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "scoring_metric = [\"accuracy\", \"recall\", \"precision\", \"f1\"]\n",
    "\n",
    "dummy_model = make_pipeline(preprocessor, DummyClassifier(strategy = \"stratified\"));\n",
    "\n",
    "results[\"dummy\"] = mean_std_cross_val_scores(dummy_model, X_train, y_train, return_train_score = True, scoring = scoring_metric);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.039 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.509 (+/- 0.019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.514 (+/- 0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.417 (+/- 0.052)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.435 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.429 (+/- 0.027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.438 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.423 (+/- 0.040)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.436 (+/- 0.006)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dummy\n",
       "fit_time         0.039 (+/- 0.008)\n",
       "score_time       0.011 (+/- 0.001)\n",
       "test_accuracy    0.509 (+/- 0.019)\n",
       "train_accuracy   0.514 (+/- 0.006)\n",
       "test_recall      0.417 (+/- 0.052)\n",
       "train_recall     0.435 (+/- 0.007)\n",
       "test_precision   0.429 (+/- 0.027)\n",
       "train_precision  0.438 (+/- 0.007)\n",
       "test_f1          0.423 (+/- 0.040)\n",
       "train_f1         0.436 (+/- 0.006)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1: Results of the baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1 indicates the results of the baseline model developed. The scores of this model are quite low, however, they can be used as a reference for the models that will be later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "\n",
    "log_reg_model = make_pipeline(preprocessor, LogisticRegression(max_iter = 1000, class_weight = \"balanced\"))\n",
    "\n",
    "results[\"Logistic Regression\"] = mean_std_cross_val_scores(log_reg_model, X_train, y_train, return_train_score = True, \n",
    "                                                           scoring = scoring_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.039 (+/- 0.008)</td>\n",
       "      <td>0.111 (+/- 0.013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.011 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.509 (+/- 0.019)</td>\n",
       "      <td>0.663 (+/- 0.040)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.514 (+/- 0.006)</td>\n",
       "      <td>0.727 (+/- 0.066)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.417 (+/- 0.052)</td>\n",
       "      <td>0.684 (+/- 0.057)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.435 (+/- 0.007)</td>\n",
       "      <td>0.755 (+/- 0.063)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.429 (+/- 0.027)</td>\n",
       "      <td>0.596 (+/- 0.039)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.438 (+/- 0.007)</td>\n",
       "      <td>0.663 (+/- 0.073)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.423 (+/- 0.040)</td>\n",
       "      <td>0.637 (+/- 0.046)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.436 (+/- 0.006)</td>\n",
       "      <td>0.706 (+/- 0.069)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dummy Logistic Regression\n",
       "fit_time         0.039 (+/- 0.008)   0.111 (+/- 0.013)\n",
       "score_time       0.011 (+/- 0.001)   0.011 (+/- 0.000)\n",
       "test_accuracy    0.509 (+/- 0.019)   0.663 (+/- 0.040)\n",
       "train_accuracy   0.514 (+/- 0.006)   0.727 (+/- 0.066)\n",
       "test_recall      0.417 (+/- 0.052)   0.684 (+/- 0.057)\n",
       "train_recall     0.435 (+/- 0.007)   0.755 (+/- 0.063)\n",
       "test_precision   0.429 (+/- 0.027)   0.596 (+/- 0.039)\n",
       "train_precision  0.438 (+/- 0.007)   0.663 (+/- 0.073)\n",
       "test_f1          0.423 (+/- 0.040)   0.637 (+/- 0.046)\n",
       "train_f1         0.436 (+/- 0.006)   0.706 (+/- 0.069)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 2: Results of baseline model and Logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model shows good promise. The scores are better than the dummy classifier, however, the scores are still pretty low. Optimising the regularisation (`C`) hyperparameter should give better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    4.6s finished\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "log_reg_param_grid = {\"logisticregression__C\": 10.0 ** np.arange(-3, 3, 1)}\n",
    "mult_metric_eval_scorer = {\"accuracy\" : \"accuracy\", \"recall\" : \"recall\", \"precision\" : \"precision\", \"f1\" : \"f1\"}\n",
    "\n",
    "log_reg_random_search = RandomizedSearchCV(log_reg_model, param_distributions = log_reg_param_grid,\n",
    "                                           n_jobs = -1, verbose = 1, scoring = mult_metric_eval_scorer, refit = \"f1\",\n",
    "                                           return_train_score = True);\n",
    "\n",
    "log_reg_random_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/ifyanene/opt/miniconda3/envs/571/lib/python3.7/site-packages/sklearn/utils/extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>logreg (tuned)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.039 (+/- 0.008)</td>\n",
       "      <td>0.111 (+/- 0.013)</td>\n",
       "      <td>0.465 (+/- 0.041)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.011 (+/- 0.000)</td>\n",
       "      <td>0.012 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.509 (+/- 0.019)</td>\n",
       "      <td>0.663 (+/- 0.040)</td>\n",
       "      <td>0.895 (+/- 0.022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.514 (+/- 0.006)</td>\n",
       "      <td>0.727 (+/- 0.066)</td>\n",
       "      <td>0.943 (+/- 0.022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.417 (+/- 0.052)</td>\n",
       "      <td>0.684 (+/- 0.057)</td>\n",
       "      <td>0.913 (+/- 0.030)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.435 (+/- 0.007)</td>\n",
       "      <td>0.755 (+/- 0.063)</td>\n",
       "      <td>0.964 (+/- 0.018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.429 (+/- 0.027)</td>\n",
       "      <td>0.596 (+/- 0.039)</td>\n",
       "      <td>0.854 (+/- 0.023)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.438 (+/- 0.007)</td>\n",
       "      <td>0.663 (+/- 0.073)</td>\n",
       "      <td>0.911 (+/- 0.031)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.423 (+/- 0.040)</td>\n",
       "      <td>0.637 (+/- 0.046)</td>\n",
       "      <td>0.883 (+/- 0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.436 (+/- 0.006)</td>\n",
       "      <td>0.706 (+/- 0.069)</td>\n",
       "      <td>0.937 (+/- 0.025)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dummy Logistic Regression     logreg (tuned)\n",
       "fit_time         0.039 (+/- 0.008)   0.111 (+/- 0.013)  0.465 (+/- 0.041)\n",
       "score_time       0.011 (+/- 0.001)   0.011 (+/- 0.000)  0.012 (+/- 0.001)\n",
       "test_accuracy    0.509 (+/- 0.019)   0.663 (+/- 0.040)  0.895 (+/- 0.022)\n",
       "train_accuracy   0.514 (+/- 0.006)   0.727 (+/- 0.066)  0.943 (+/- 0.022)\n",
       "test_recall      0.417 (+/- 0.052)   0.684 (+/- 0.057)  0.913 (+/- 0.030)\n",
       "train_recall     0.435 (+/- 0.007)   0.755 (+/- 0.063)  0.964 (+/- 0.018)\n",
       "test_precision   0.429 (+/- 0.027)   0.596 (+/- 0.039)  0.854 (+/- 0.023)\n",
       "train_precision  0.438 (+/- 0.007)   0.663 (+/- 0.073)  0.911 (+/- 0.031)\n",
       "test_f1          0.423 (+/- 0.040)   0.637 (+/- 0.046)  0.883 (+/- 0.025)\n",
       "train_f1         0.436 (+/- 0.006)   0.706 (+/- 0.069)  0.937 (+/- 0.025)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg_model = log_reg_random_search.best_estimator_;\n",
    "\n",
    "results[\"Logistic Regression (tuned)\"] = mean_std_cross_val_scores(best_log_reg_model, X_train, y_train, return_train_score = True,\n",
    "                                                      scoring = scoring_metric);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>logreg (tuned)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.039 (+/- 0.008)</td>\n",
       "      <td>0.111 (+/- 0.013)</td>\n",
       "      <td>0.465 (+/- 0.041)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.011 (+/- 0.000)</td>\n",
       "      <td>0.012 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.509 (+/- 0.019)</td>\n",
       "      <td>0.663 (+/- 0.040)</td>\n",
       "      <td>0.895 (+/- 0.022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.514 (+/- 0.006)</td>\n",
       "      <td>0.727 (+/- 0.066)</td>\n",
       "      <td>0.943 (+/- 0.022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.417 (+/- 0.052)</td>\n",
       "      <td>0.684 (+/- 0.057)</td>\n",
       "      <td>0.913 (+/- 0.030)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.435 (+/- 0.007)</td>\n",
       "      <td>0.755 (+/- 0.063)</td>\n",
       "      <td>0.964 (+/- 0.018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.429 (+/- 0.027)</td>\n",
       "      <td>0.596 (+/- 0.039)</td>\n",
       "      <td>0.854 (+/- 0.023)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.438 (+/- 0.007)</td>\n",
       "      <td>0.663 (+/- 0.073)</td>\n",
       "      <td>0.911 (+/- 0.031)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.423 (+/- 0.040)</td>\n",
       "      <td>0.637 (+/- 0.046)</td>\n",
       "      <td>0.883 (+/- 0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.436 (+/- 0.006)</td>\n",
       "      <td>0.706 (+/- 0.069)</td>\n",
       "      <td>0.937 (+/- 0.025)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dummy Logistic Regression     logreg (tuned)\n",
       "fit_time         0.039 (+/- 0.008)   0.111 (+/- 0.013)  0.465 (+/- 0.041)\n",
       "score_time       0.011 (+/- 0.001)   0.011 (+/- 0.000)  0.012 (+/- 0.001)\n",
       "test_accuracy    0.509 (+/- 0.019)   0.663 (+/- 0.040)  0.895 (+/- 0.022)\n",
       "train_accuracy   0.514 (+/- 0.006)   0.727 (+/- 0.066)  0.943 (+/- 0.022)\n",
       "test_recall      0.417 (+/- 0.052)   0.684 (+/- 0.057)  0.913 (+/- 0.030)\n",
       "train_recall     0.435 (+/- 0.007)   0.755 (+/- 0.063)  0.964 (+/- 0.018)\n",
       "test_precision   0.429 (+/- 0.027)   0.596 (+/- 0.039)  0.854 (+/- 0.023)\n",
       "train_precision  0.438 (+/- 0.007)   0.663 (+/- 0.073)  0.911 (+/- 0.031)\n",
       "test_f1          0.423 (+/- 0.040)   0.637 (+/- 0.046)  0.883 (+/- 0.025)\n",
       "train_f1         0.436 (+/- 0.006)   0.706 (+/- 0.069)  0.937 (+/- 0.025)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 3: Results of Baseline, Logistic regression, and regularisation optimised logistic regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After ooptimising the regularisation hyperparameter, much better s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a name=\"References\"></a>\n",
    "\n",
    "de Jonge, E., 2020. CRAN - Package Docopt. [online] Cran.r-project.org. Available at: https://cran.r-project.org/web/packages/docopt/index.html [Accessed 29 November 2020].\n",
    "\n",
    "Oliphant, T.E., 2006. A guide to NumPy, Trelgol Publishing USA.\n",
    "\n",
    "McKinney, W. & others, 2010. Data structures for statistical computing in python. In Proceedings of the 9th Python in Science Conference. pp. 51–56.\n",
    "\n",
    "Waskom, M. et al., 2017. mwaskom/seaborn: v0.8.1 (September 2017), Zenodo. Available at: https://doi.org/10.5281/zenodo.883859.\n",
    "\n",
    "Van Rossum, G. & Drake, F.L., 2009. Python 3 Reference Manual, Scotts Valley, CA: CreateSpace.\n",
    "\n",
    "Hunter, J.D., 2007. Matplotlib: A 2D graphics environment. Computing in science & engineering, 9(3), pp.90–95.\n",
    "\n",
    "Pedregosa, F. et al., 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), pp.2825–2830.\n",
    "\n",
    "P'erez, Fernando & Granger, B.E., 2007. IPython: a system for interactive scientific computing. Computing in Science & Engineering, 9(3).\n",
    "\n",
    "Kluyver, T. et al., 2016. Jupyter Notebooks – a publishing format for reproducible computational workflows. In F. Loizides & B. Schmidt, eds. Positioning and Power in Academic Publishing: Players, Agents and Agendas. pp. 87–90.\n",
    "\n",
    "Anon, 2020. Anaconda Software Distribution, Anaconda Inc. Available at: https://docs.anaconda.com/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
